{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<div>\n<img src=\"figures/svtLogo.png\"/>\n</div>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center><h1>Mathematical Optimization for Engineers</h1></center>\n<center><h2>Lab 5 - KKT Conditions of Optimality</h2></center>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### KKT conditions for equality-constrained problems\n\nWe consider the following optimization problem \n\n$$\\begin{aligned}\n\\displaystyle \\min_{x_1,x_2} \\;\\; &x_1+x_2 \\\\\n\\mbox{s.t. } \\; &x_2=x_1 ^2-2.\n\\end{aligned}$$",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 1</u>: Reformulate the optimization problem with the general nomenclature\nof the Lecture in terms of $f$ and $c_{i}$.\n\nLet $\\mathbf {x}$ = [x1, x2], then\n\nmin($\\mathbf {x}$)\n$c_i$($\\mathbf {x}$) $\\le$ 0 for all i in I\n$c_i$ = 0 for all i in E\n\n$c_i$(x1, x2) = x2 - x1 ** 2 + 2",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 2</u>: What are the gradients of the objective function and the equality\nconstraint function?\n\ngrad(f) = (1, 1), grad(c) = (-2x_1, 1)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 3</u>: Sketch the feasible region of the optimization problem for\n$x_1 \\in [-2,2]$ and $x_2 \\in [-2,3]$; add the contour lines of the\nobjective function; add the direction of the gradients of the\nobjective function and the equality constraint.\n\n(done on paper)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 4</u>: Set up the Langrangian function for this optimization problem\n\nL(x1, x2, l) = x1 + x2 + l*(x2 - x1^2 + 2)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 5</u>: Write down the KKT-conditions with respect to this optimization\nproblem\n\na) L(x1, x2, l) = 0 <br>\nx1 + x2 + l*(x2 - x1^2 + 2) = 0 <br>\n(1, 1) + l*(-2x1, 1) = (0, 0)\n\n1 + -2lx1 = 0 <br>\n1 + l = 0 <br>\n\nb) x2 - x1^2 + 2 = 0",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 6</u>: Solve manually the KKT-conditions for $x_1$, $x_2$ and the Lagrange\nmultiplier.\n\n1 + l = 0 => l = -1 <br>\n1 + -2lx1 = 0 => x1 = -1/2\n\n\nx2 - x1^2 + 2 = 0 => x2 = -7/4",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 7</u>: Solve numerically (with `fsolve` from scipy.optimize) the KKT-conditions for\n$x_1$, $x_2$ and the Lagrange multiplier.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from scipy import optimize as opt\nimport numpy as np\n\ndef kkt_conditions(y):\n    conditions = np.zeros(len(y))\n    x1 = y[0]\n    x2 = y[1]\n    l = y[2]\n    \n    conditions[0] = 1 - 2*l*x1\n    conditions[1] = 1 + l\n    conditions[2] = x2 - x1**2 + 2\n    \n    return conditions\n    \n\ny0 = np.array([-1.0, -1.0, -1.0]) # initial guess \n\nres = opt.fsolve(kkt_conditions, y0, full_output=False)\n\nprint (\"x1 = {:.2f} \\nx2 = {:.2f} \\nl = {:.2f}\".format(res[0],res[1],res[2]))",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": "x1 = -0.50 \nx2 = -1.75 \nl = -1.00\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### KKT conditions for inequality-constrained problems\n\nWe consider the following optimization problem \n\n$$\\begin{aligned}\n\\displaystyle \\min_{x_1,x_2} \\quad &x_1+x_2 \\\\\n\\mbox{s.t. } \\; &x_1 \\geq -2 \\\\\n&x_2  \\geq -2\n\\end{aligned}$$",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 1</u>: Reformulate the optimization problem with the general nomenclature\nof the Lecture in terms of $f$ and $c_{i}$.\n\nf(x1, x2) = x1 + x2\n\nc_i(x1, x2) = ((-x1 - 2), (-x2 - 2))",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 2</u>: -   What are the gradients of the objective function and the inequality constraints?\n\ngrad(f) = (1, 1)\n\ngrad(c1) = (-1, 0)\n\ngrad(c1) = (0, -1)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 3</u>: -   Sketch the feasible region of the optimization problem for\n$x_1 \\in [-3,1]$ and $x_2 \\in [-3,1]$; add the contour lines of the\nobjective function; add the direction of the gradients of the\nobjective function and the inequality constraints.\n\n(done on paper)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 4</u>: Set up the Langrangian function for this optimization problem\n\nL(x1, x2, l1, l2) = x1 + x2 + l1*(-x1 - 2) + l2*(-x2 - 2)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 5</u>: Write down the KKT-conditions with respect to this optimization\nproblem\n\na) L(x1, x2, l1, l2) = 0 <br>\nx1 + x2 + l1*(-x1 - 2) + l2*(-x2 - 2) = 0 <br>\n\n1 - l1 = 0 => l1 = 1 <br>\n1 - l2 = 0 => l2 = 1 <br>\n\nb) x1 + 2 $\\ge$ 0 <br>\nx2 + 2 $\\ge$ 0 <br>\n\nc) l1, l2 $\\ge$ 0 <br>\n\nd) l1*(-x1 - 2) = 0 <br>\nl2*(-x2 - 2) = 0 <br>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 6</u>: Solve manually the KKT-conditions for $x_1$, $x_2$ and the Lagrange\nmultiplier.\n\na,d => x1, x2 = -2",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### A degenerate case\n\nWe consider the following optimization problem \n\n$$\\begin{aligned}\n\\displaystyle \\min_{x_1,x_2} \\quad &x_1 \\\\\n\\mbox{s.t. } \\;  &x_{2} \\leq 0 \\\\\n&x_{1}^{2} - x_{2} \\leq 0\\,.\n\\end{aligned}$$",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 1</u>: Write down the KKT-conditions with respect to this optimization\nproblem\n\nL(x1, x2, l1, l2) = x1 + l1*x2 + l2*(x1^2 - x2)<br>\n\nKKT: <br>\na) x1 + l1*x2 + l2*(x1^2 - x2 = 0 <br>\n1 - 2x1l2 = 0 <br>\nl1 - l2 = 0 => l1 = l2<br>\n\nb) x2 $le$ 0 <br>\nx1^2 - x2 $le$ 0 <br>\n\nc) l1 * x2 = 0 <br>\nl2*(x1^2 - x2) = 0 <br>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 2</u>: Solve manually the KKT-conditions for $x_1$, $x_2$ and the Lagrange\nmultipliers.\n\na => 2 cases <br>\n1) l = 0 => 1 = 0 <br>\n2) l > 0 => x1,x2 = 0 => 1 = 0<br>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 3</u>: Sketch the feasible region of the optimization problem; add the contour lines of the\nobjective function; add the direction of the gradients of the objective function and the constraints. Where is the optimum?\n\n(done on paper)",
      "metadata": {}
    }
  ]
}