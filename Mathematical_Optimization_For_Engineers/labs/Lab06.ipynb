{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<div>\n<img src=\"figures/svtLogo.png\"/>\n</div>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center><h1>Mathematical Optimization for Engineers</h1></center>\n<center><h2>Lab 6 - The Simplex Method</h2></center>\n\nConsider the following optimization problem:\n\n$$\\min_{x_1,x_2} \\quad \\quad x_1+x_2$$\n\n$$\\begin{aligned}\n\\mbox{s.t. }\\quad 0 \\; \\leq \\; x_1 \\; &\\leq \\; 1\\\\\n0 \\; \\leq \\; x_2 \\; &\\leq \\; 1\\\\\nx_1+x_2 \\; &\\leq \\; 1.5\\\\\n\\end{aligned}$$\n\n<u>Task 1</u>: Sketch the feasible region for this problem. Where is the optimal solution?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nregion = np.linspace(-3,3,300)\nx,y = np.meshgrid(d,d)\nplt.imshow(((x >= 0) & (y >= 0) & (x <= 1) & (y <= 1) & \n            (x + y <= 1.5)).astype(int) , extent=(x.min(),x.max(),y.min(),y.max()),\n            origin=\"lower\", cmap=\"Greys\", alpha = 0.3);\n\n\nx, y = np.linspace(-1, 2, 500), np.linspace(-1, 2, 500)\n\ny1, y2 = 0, 1\nx1, x2 = 0, 1\ny3 = -x + 1.5\n\nplt.plot(x, 0*np.ones_like(x), label=r'$x2=0$')\nplt.plot(x, 1*np.ones_like(x), label=r'$x2=1$')\nplt.plot(0*np.ones_like(y), y, label=r'$x1=0$')\nplt.plot(1*np.ones_like(y), y, label=r'$x1=1$')\nplt.plot(x, y3, label=r'$x2 = -x1 + 1.5$')\nplt.plot(0, 0, '-o', label=r'minimum')\nplt.xlim(-0.5,1.5)\nplt.ylim(-0.5,1.5)\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 2</u>: Introduce slack variables and reformulate the optimization problem into standard form:\n\n$$\\begin{aligned}\n\\min_{\\bar{\\mathbf x}} \\quad \\bar{\\mathbf{d}}^{T} \\bar{\\mathbf x} \\\\\n\\mbox{s.t.} \\quad \\bar{\\mathbf A} \\bar{\\mathbf x} &= \\bar{\\mathbf b} \\\\\n\\bar{\\mathbf x} &\\geq \\mathbf{0}\n\\end{aligned}$$\n\na) for x1 $\\le$ 0: <br>\nintroduce t1 s.t. x1 + t1 = 0 => t1 $\\ge$ 0\n\nb) for x2 $\\le$ 0: <br>\nintroduce t2 s.t. x2 + t2 = 0 => t2 $\\ge$ 0\n\nc) for x1 + x2 $\\le$ 1.5: <br>\nintroduce t3 s.t. x1 + x2 + t3 = 1.5 => t3 $\\ge$ 0\n\nx_bar = (x1, x2, t1, t2, t3) <br>\nd_bar = (1, 1, 0, 0, 0) # objective func\n\nA_bar(a, b, c) = ((1, 0, 1, 0, 0), (0, 1, 0, 1, 0), (1, 1, 0, 0, 1))",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 3</u>: Determine the values of $\\bar{\\mathbf x}$ for the points $\\mathbf x=(0,1)^T$, $\\mathbf x=(1,0.5)^T$, and $\\mathbf x=(0,0)^T$. What are the corresponding basic matrices $\\mathbf{B}$?\n\na) for (0, 1): <br>\nx_bar = (0, 1, 1, 0, 0.5)\n\nb) for (1, 0.5): <br>\nx_bar = (1, 0.5, 0, 0.5, 0)\n\nc) for (0, 0): <br>\nx_bar = (0, 0, 1, 1, 0.5)\n\ni) for (0, 1): 2, 3, 5 columns<br>\n\n\nii) for (1, 0.5): 1, 2, 4 cols<br>\n\n\niii) for (0, 0): 3, 4, 5 cols<br>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<u>Task 4</u>: Answer the following:\n\n1. How does the Simplex method work?\n<br>\nIt iterates through corners of a polytope from one corner to the neigboring corner where the objective function decreases by most\n<br>\n2. How do we know, if the current corner point is the optimal one? Which condition has to hold? Derive it from the KKT conditions.\n<br>\nFrom the KKT conditions we can say that the method stops when the Lagrange multipliers become $\\ge$ 0\n<br>\n3. If we have not found the optimal corner point yet: which column has to be included into the basis matrix $\\mathbf {B}$? Which column must be excluded from $\\mathbf {B}$?\n\nAssuming that at least one of the l_I,N is negative, the column corresponding to the lowest l_I,N can be included in B (Dantzig).\n\nWe can determine the column to delete from B using the formula: <br>\n\nx_b^+ = x_b\n\n−B^−1*A_q*x_q^+\n\nThe entry of x_b^+ which becomes 0 first is the column we need to delete",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<b>We will now implement the Simplex method in Python. </b>\n\nAt the outset, let's declare the matrices we have defined in the exercise above:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom numpy.linalg import inv\nfrom numpy.matlib import matrix\n\n# equality constraints LHS\nA = np.matrix([[1,0,1,0,0], [0,1,0,1,0], [1,1,0,0,1]])\n# equality constraints RHS\nb = np.array([1, 1, 1.5])\n# objective\nd = np.array([1, 1, 0, 0, 0])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The Simplex method needs a <u>feasible corner point</u> to start with. We do not cover in this course, how such a point is found. Here, we are able to guess one because the problem is small.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# initial point\nx_init = np.array([1,0.5,0,0.5,0])\n# corresponding initial Basic Feasible Set \n# (note that indexing in Python starts from 0)\nbasic_init = [0,1,3]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We will now implement the following pseudo-code, that we saw in the lecture:\n<br>\n<br>\nWhile not($\\lambda_{I,N} \\geq \\mathbf 0$)\n1. Choose an index $q \\notin T^k(\\mathbf x)$ such that $$q = \\underset{i \\notin T^k(\\mathbf x)}{\\operatorname{argmin}}\\mathbf \\lambda_{I,i}$$\n<br>\n$$\\mathbf \\lambda_{I,q} = \\underset{i \\notin T^k(\\mathbf x)}{\\operatorname{min}}\\mathbf \\lambda_{I,i}$$\n<br>\n2. Increase $x_q$, following $\\mathbf A \\mathbf x^+ = \\mathbf b$, until some $x_p^+$ with $p \\in T(\\mathbf x)$ becomes zero. <br>\n<br>\n$$\\implies x_q^+ = \\underset{i \\in T^k(\\mathbf x)|(\\mathbf B^{-1} \\mathbf A_q)_i \\gt 0}{\\operatorname{min}} (\\mathbf x_B)_i/(\\mathbf B^{-1} \\mathbf A_q)_i$$\n<br>\n$$\\implies p = \\underset{i \\in T^k(\\mathbf x)|(\\mathbf B^{-1} \\mathbf A_q)_i \\gt 0}{\\operatorname{argmin}} (\\mathbf x_B)_i/(\\mathbf B^{-1} \\mathbf A_q)_i$$\n<br>\n3. Update $\\mathbf x$, basic set and non-basic set.$$\\mathbf x_B^{+} = \\mathbf x_B - \\mathbf B^{-1} \\mathbf A_q x_q^+ $$\n<br>\n<br>\n<i>Note that we are working with LP notation in <u>standard form</u>, even though we have dropped the bars for the sake of clarity.</i>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let us now write the core function. Our implementation takes the follwoing as inputs:\n\n1. Matrix $\\bar{\\mathbf A}$ \n2. Cost vector $\\bar{\\mathbf d}$  \n3. An initial point \n4. The corresponding initial Basic Feasible Set \n\nIt returns the following:\n\n1. Optimal value of $\\bar{\\mathbf x}$ \n2. The corresponding Basic Feasible Set\n3. The optimal cost",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def simplex_method(A: matrix, c: np.array, x: np.array, basic: list):\n    \n    # clear all\n    lambda_i_q, q, p, x_q_plus = None, None, None, None\n    \n    m, n = A.shape[0], A.shape[1]  # no. of rows, columns of A, respectively\n    nonbasic = set(range(n)) -set(basic)  # Non-basic index set\n    \n    obj = np.dot(c, x)  # Value of obj. function\n    \n    optimum = False # boolean for termination\n    iter = 1 # iteration counter\n    \n    \n    # main iterative loop\n    \n    while not optimum:\n        \n        # inverse of basic matrix - can be made efficient by updating B_inv\n        # instead of recomputing in each iteration\n        B_inv = inv(A[:, basic])\n        \n        # step 1: choose index q by Dantzig's rule\n        lambda_i_q, q = min([((c[q] - c[basic]*B_inv* A[:,q]).item(), q) for q in nonbasic],\n                         key=(lambda tup: tup[0]))\n        \n        optimum = (lambda_i_q >= 0)\n        \n        if optimum:\n            print(\"\\tfound optimum\")\n            return x, set(basic), obj  # Found optimal solution\n        \n        # step 2: calculate leaving index p and x_q_plus\n        \n        x_q_plus, p = min([(x[basic][i] / (B_inv[i, :]*A[:, q]).item(), i) for i in range(m) if (B_inv[i, :]*A[:, q]).item() > 0], key=(lambda tup: tup[0]))\n        \n        # step 3: update x\n        \n        x[basic] = x[basic] - x_q_plus*np.array([(B_inv[i, :] * A[:, q]).item() for i in range(m)])\n        x[q] = x_q_plus\n        assert x[basic][p] == 0\n        \n        obj = obj + x_q_plus*lambda_i_q\n        \n        nonbasic = nonbasic - {q} | {basic[p]}\n        basic = list(set(range(n)) - nonbasic)\n        \n        # print iteration log\n        \n        print(\n            \"Iteration {}: \\tq = {:d} \\tlambda_i_q = {:.2f} \\tp = {:d} \\tx_q_plus = {:.4f} \\tobj = {:.2f}\"\n                .format(iter, q+1, lambda_i_q, p+1, x_q_plus, obj)\n        )\n        \n        print(\"x = {}\\n\".format(x))\n        \n        iter += 1\n        \n        # end loop",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(\"Iteration {}:\".format(0))\nprint(\"x0 = {}\\n\".format(x_init))\n\nxopt, basic, obj = simplex_method(A, d, x_init, basic_init)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Geometrical interpretation",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Geometrically speaking, the Simplex method moves along an edge of the feasible polytope that decreases $\\mathbf c^T \\mathbf x$. It continues to move along this edge until a new vertex is encountered. At this vertex, a new constraint $x_p \\ge 0$ must have become active, that is, one of the components $x_p, p \\in T(\\mathbf x)$, has decreased to zero. We then remove this index $p$ from the basis $T(\\mathbf x)$ and replace it by $q$.\n\nBy looking at the figure below, we can tell that at the initial point, $\\mathbf x^0$, the constraints $x_5 \\ge 0$ and $x_3 \\ge 0$ are active. The optimizer picks $q=5$ as the entering index (as per Dantzig's rule) and $p=2$ as the leaving index. Note that at the the first iterate, $\\mathbf x^1$, the constraints $x_2 \\ge 0$ and $x_3 \\ge 0$ are active.\n\nConvince yourself that the above applies to the second step as well!\n<br>\n<br>\n<div>\n<img src=\"figures/step.png\" width=\"400\"/>\n</div>\n<br>\n<br>\nThis is the reason that Simplex method is called an active-set method - it approches the minimum via the boundary of the feasible set.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}